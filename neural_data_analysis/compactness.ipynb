{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pickle\n",
    "from tqdm import tqdm \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import copy\n",
    "\n",
    "\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from scipy.optimize import curve_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions \n",
    "###### helper functions ####### \n",
    "def pkl_read(file_to_read, write_dir):\n",
    "  this = pickle.load(open(os.path.join(write_dir,file_to_read), \"rb\"))\n",
    "  # print(this)\n",
    "  return this\n",
    "\n",
    "def pkl_write(file_to_write, values_to_dump, write_dir):\n",
    "  os.chdir(write_dir)\n",
    "  with open(os.path.join(write_dir,file_to_write), 'wb') as pickle_file:\n",
    "      pickle.dump(values_to_dump, pickle_file)\n",
    "\n",
    "def getdata_day(data,id,data_day):\n",
    "  if id == 1:\n",
    "    # var_name = data[0:data_day[id]+1,:,:]\n",
    "    var_name = data[0:data_day[id],:,:]\n",
    "  else:\n",
    "    day_idx = np.where(np.array(list(data_day))== id)[0].astype(int) - 1\n",
    "    #print(day_idx[0])\n",
    "    prev_day_id = list(data_day)[day_idx[0]]\n",
    "    #print(prev_day_id)\n",
    "    var_name = data[data_day[prev_day_id]:data_day[id],:,:]\n",
    "  return var_name\n",
    "\n",
    "def gettarget_day(target_direction, id, day):\n",
    "    if id == 1: \n",
    "      target = target_direction[:day[id]]\n",
    "    else:\n",
    "      day_idx = np.where(np.array(list(day))== id)[0].astype(int) - 1\n",
    "      #print(day_idx[0])\n",
    "      prev_day_id = list(day)[day_idx[0]]\n",
    "      target = target_direction[day[prev_day_id]:day[id]] \n",
    "    return target\n",
    "\n",
    "def get_numtrials_perday(datasize_day):\n",
    "    '''\n",
    "    datasize_day: dictionary with key as day and value as end trial index for that day . Comes from getdata_day()\n",
    "    '''\n",
    "    num_trials_perday = np.zeros(len(datasize_day))\n",
    "    num_trials_perday[0] = np.array(list(datasize_day.values()))[0]\n",
    "    num_trials_perday[1:] = np.diff(np.array(list(datasize_day.values())))\n",
    "    # print(num_trials_perday)\n",
    "    return num_trials_perday\n",
    "\n",
    "def trial_concatenate_data(data):\n",
    "    '''\n",
    "    data is on shape n_trials x n_units x n_bins \n",
    "    '''\n",
    "    n,u,t = data.shape\n",
    "    new_arr = np.transpose(data, (0,2,1))\n",
    "    new_arr = new_arr.reshape(n*t, u)\n",
    "    # print(new_arr.shape)\n",
    "    return new_arr \n",
    "\n",
    "###### LR analysis functions #########\n",
    "\n",
    "def get_equal_target_dist_predefinedsplit(idx, target, n_samples_per_target):\n",
    "  random_idx = []\n",
    "  for it in range(8):\n",
    "    this_idx = np.where(target== it+1)\n",
    "    \n",
    "    r_idx = np.random.choice(this_idx[0], n_samples_per_target, replace = False)\n",
    "    # print(r_idx)\n",
    "    random_idx.append(r_idx)\n",
    "  # print(np.shape(random_idx))\n",
    "  rand_idx = np.array(random_idx).reshape(n_samples_per_target*8)\n",
    "  ps = np.zeros(len(target))\n",
    "  ps[rand_idx] = -1 # index for training \n",
    "  # ps[ps == 0] = 1 # index for test set\n",
    "\n",
    "  # to genereate 2 fold cross validation\n",
    "  test_idx = np.argwhere(~np.in1d(np.arange(len(ps)), rand_idx))\n",
    "  first_fold = test_idx[:len(test_idx)//2]\n",
    "  second_fold = test_idx[len(test_idx)//2:]\n",
    "  ps[first_fold] = 0   # index for test set for fold 1\n",
    "  ps[second_fold] = 1 # index for test set for fold 2\n",
    "  print(ps[ps == -1].shape, ps[ps == 0].shape, ps[ps == 1].shape)\n",
    "  return ps\n",
    "\n",
    "def flatten_data(data):\n",
    "    # Flattens the last two dimensions of the data\n",
    "    return data.reshape(data.shape[0], -1)\n",
    "\n",
    "\n",
    "def matrix_similarity(A, B):\n",
    "    \"\"\"\n",
    "    Compute the R^2 similarity between two matrices by treating them as vectors.\n",
    "\n",
    "    Args:\n",
    "    - A: First 2D matrix.\n",
    "    - B: Second 2D matrix.\n",
    "\n",
    "    Returns:\n",
    "    - R^2 value representing the similarity between the matrices.\n",
    "    \"\"\"\n",
    "    assert A.shape == B.shape, \"Matrices must have the same shape\"\n",
    "\n",
    "    # Flatten the matrices to vectors\n",
    "    A_flat = A.ravel()\n",
    "    B_flat = B.ravel()\n",
    "\n",
    "    # Compute the correlation coefficient\n",
    "    correlation_matrix = np.corrcoef(A_flat, B_flat)\n",
    "    r = correlation_matrix[0, 1]\n",
    "    \n",
    "    # Square the correlation coefficient to get R^2 value\n",
    "    r2 = r #**2\n",
    "    return r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_recordings = pkl_read('neural_data.pkl', './example_data/') # Shape: n_tr x n_units x n_timebins; top 16 units are readouts \n",
    "target_direction = pkl_read('target_labels.pkl', './example_data/')\n",
    "datasize_day = pkl_read('trial_day_label.pkl', './example_data/')\n",
    "\n",
    "days = [2,3,4,5,6,7] # just for example. In the paper, we considered all days that had a minimum of 25 trials of successful reaches per target direction, minimum 200 trials in total.  \n",
    "n_readouts = 20\n",
    "decoder_change_days = [0,0,0,0,0,1]\n",
    "unit_swap_day = [0,0,0,0,0,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

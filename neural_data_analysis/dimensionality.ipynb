{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### helper functions ####### \n",
    "def pkl_read(file_to_read, write_dir):\n",
    "  os.chdir(write_dir)\n",
    "  this = pickle.load(open(file_to_read, \"rb\"))\n",
    "  # print(this)\n",
    "  return this\n",
    "\n",
    "def pkl_write(file_to_write, values_to_dump, write_dir):\n",
    "  os.chdir(write_dir)\n",
    "  with open(file_to_write, 'wb') as pickle_file:\n",
    "      pickle.dump(values_to_dump, pickle_file)\n",
    "\n",
    "def getdata_day(data,id,data_day):\n",
    "  if id == 1:\n",
    "    # var_name = data[0:data_day[id]+1,:,:]\n",
    "    var_name = data[0:data_day[id],:,:]\n",
    "  else:\n",
    "    day_idx = np.where(np.array(list(data_day))== id)[0].astype(int) - 1\n",
    "    #print(day_idx[0])\n",
    "    prev_day_id = list(data_day)[day_idx[0]]\n",
    "    #print(prev_day_id)\n",
    "    var_name = data[data_day[prev_day_id]:data_day[id],:,:]\n",
    "  return var_name\n",
    "\n",
    "def gettarget_day(target_direction, id, day):\n",
    "    if id == 1: \n",
    "      target = target_direction[:day[id]]\n",
    "    else:\n",
    "      day_idx = np.where(np.array(list(day))== id)[0].astype(int) - 1\n",
    "      #print(day_idx[0])\n",
    "      prev_day_id = list(day)[day_idx[0]]\n",
    "      target = target_direction[day[prev_day_id]:day[id]] \n",
    "    return target\n",
    "\n",
    "\n",
    "###### analysis functions #########\n",
    "\n",
    "def calculate_PR(data, normalize_pr = True, normalize_data = 'zscore', sqrt_transform = False ):\n",
    "    '''\n",
    "    Args: \n",
    "    data (2D Numpy array): Neural data in format (n_timepoints, n_units)\n",
    "    '''\n",
    "    # n_t, n_u = data.shape\n",
    "    if  normalize_data == 'zscore': \n",
    "        scaler_ = StandardScaler()\n",
    "        standardized_data = scaler_.fit_transform(data)\n",
    "        data = standardized_data\n",
    "    if normalize_data  == 'demean':\n",
    "        scaler_ = StandardScaler(with_mean = True, with_std = False)\n",
    "        standardized_data = scaler_.fit_transform(data)\n",
    "        data = standardized_data\n",
    "#         print(scaler_.mean_)\n",
    "        \n",
    "    if sqrt_transform:\n",
    "        data = np.sqrt(data + 0.375)  # see Kihlberg, 1972; 0.386 could also be a good value\n",
    "            \n",
    "    C_unit = np.cov(data.T)\n",
    "#     print(C_unit.shape)\n",
    "    eig_val, eig_vec = np.linalg.eig(C_unit)\n",
    "    PR = (np.sum(eig_val))**2/ np.sum(eig_val**2)\n",
    "    return (PR - 1) / (data.shape[1] - 1) if normalize_pr else PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_recordings = pkl_read('neural_data.pkl', '.')\n",
    "target_direction = pkl_read('target_labels.pkl', '.')\n",
    "days_wtrials = pkl_read('trial_day_label.pkl', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error bars for Global PR from 1000 draws on all trials\n",
    "n_bs = 10 \n",
    "normalize_data = 'demean'\n",
    "\n",
    "g_normPR_all_bs = np.zeros((n_bs, len(days_wtrials)))\n",
    "g_normPR_r_bs = np.zeros((n_bs, len(days_wtrials)))\n",
    "g_normPR_nr_bs = np.zeros((n_bs, len(days_wtrials)))\n",
    "\n",
    "l_normPR_all_bs = np.zeros((n_bs, len(days_wtrials), 8))\n",
    "l_normPR_r_bs = np.zeros((n_bs, len(days_wtrials), 8))\n",
    "l_normPR_nr_bs = np.zeros((n_bs, len(days_wtrials), 8))\n",
    "\n",
    "\n",
    "for idraw in tqdm(range(n_bs)): \n",
    "\n",
    "\n",
    "      for id, iday in tqdm(enumerate(unique_bmi_day[days_wtrials])): \n",
    "            # per day\n",
    "            data_all = getdata_day(neural_recordings,iday, datasize_day )\n",
    "            target = gettarget_day(target_direction, iday, datasize_day)\n",
    "            # print(np.unique(target))\n",
    "            if id == early_day_idx:\n",
    "                  data_early = data_all\n",
    "            if id == late_day_idx:\n",
    "                  data_late = data_all\n",
    "\n",
    "            data = trial_concatenate_data(data_all)\n",
    "            # print(data.shape)\n",
    "\n",
    "            g_normPR_all_bs[idraw, id] = calculate_PR(data, normalize_pr= True, normalize_data=normalize_data, sqrt_transform=False)\n",
    "            g_normPR_r_bs[idraw, id] = calculate_PR(data[:, :direct_idx_2.shape[0]], normalize_pr= True, normalize_data=normalize_data, sqrt_transform=False)\n",
    "            g_normPR_nr_bs[idraw, id] = calculate_PR(data[:, direct_idx_2.shape[0]:], normalize_pr= True, normalize_data=normalize_data, sqrt_transform=False)\n",
    "\n",
    "            # for it in np.unique(target).astype(int):\n",
    "            #       it_idx = np.where(target[idx] == it)[0]\n",
    "            #       data_it = data_idx[it_idx,:,:]\n",
    "            #       data_it = trial_concatenate_data(data_it)\n",
    "            #       # print(data.shape, it)\n",
    "\n",
    "            #       l_normPR_all_bs[idraw, id, it-1] = calculate_PR(data_it, normalize_pr= True, normalize_data=normalize_data, sqrt_transform=False)\n",
    "            #       l_normPR_r_bs[idraw, id, it-1] = calculate_PR(data_it[:, :direct_idx_2.shape[0]], normalize_pr= True, normalize_data=normalize_data, sqrt_transform=False)\n",
    "            #       l_normPR_nr_bs[idraw, id, it-1] = calculate_PR(data_it[:, direct_idx_2.shape[0]:], normalize_pr= True, normalize_data=normalize_data, sqrt_transform=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

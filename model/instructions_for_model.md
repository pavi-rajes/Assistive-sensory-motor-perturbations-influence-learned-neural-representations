# BCI model
Simulation of a BCI center-out reaching task using a recurrent neural network (RNN) and reinforcement learning. The RNN can control either an arm model or a cursor.
At the moment, only 2D reaching tasks are supported.


# Dependencies
* Eigen 3.3.9 or 3.4.0 (https://eigen.tuxfamily.org/dox-3.3/)
* Conda env file `analysis/environment.yml`contains the python dependencies. You'll have to activate the environment before starting a simulation (`source activate bmi_model`).


# Content of the repository
*`src/` : contains source files

*`sim/`: contains `sim_*.cpp` files, `run_*.sh` files and the Makefile.

*`params/`: contains informations about simulation parameters

*`analysis/`: contains Python classes and scripts to analyze data generated by the simulations


# Compilation
Compilation is managed by `make`. In `sim/Makefile`, you'll have to provide the correct path for Eigen. You'll have to remove the references to OpenMP in the Makefile if you don't have access to it.


# Structure of a simulation
Each simulation is put in a `sim_*.cpp` file; this file contains the `main()`. Associated with each sim file is a `run_*.sh` bash script that handles read/write operations and directory creations, calls `make` and executes the simulation of the associated `sim_*.cpp` file.

Typical simulation phases:
1. Pre-training the model on the manual control task, to mimic the fact that, in experiments, the non-human primate is typical familiar with the task prior to BCI training. Also, it helps establish an ``inductive bias’’ for the network weights.
2. Fitting the decoder to simulation data under manual control, to build a biomimetic BCI decoder. 
3. Learning under BCI control (might involve interspaced manual retraining to maintain manual-control performance).

# Detailed instructions for model simulation
1. Open the makefile (`sim/Makefile`) and change the location of the OpenMP and Eigen librairies. (OpenMP can be omitted.)
2. Go to `sim` folder and run `make`. This will compile and link the code in `src`. 
3. Use `chmod u+x run_arm_model.sh` and `chmod u+x run_bci_model.sh` to make these executable. You can open the `.sh` files to modify some of the simulation parameters. We have set the number of seeds to 1 (10 was used in the paper) because each simulation is quite long.
4. Execute `./run_arm_model` to learn the center-out reaching task with the arm model. 
5. Execute `./run_bci_model` to learn the center-out reaching task with the BCI.

Note that the simulations will produce a number of data file in a folder `data` (created automatically) and also some results (like arm or cursor trajectories) in folder `results`. Also, copies of the simulation parameters are saved in a `params` folder.

# Analysis
* Panels of Fig. 5B in the paper are produce automatically when running the model. We selected a nice-looking seed among the 10 seeds we simulated. 
* To produce Fig. 5C-D, run `plot_loss_with_and_no_clda_constant_days.py`.
* Figure 5E-F: run `ndc_single_unit_ranked_based.py`.
* Figure 5G: run `synergy_constant_days.py` 
* Figure 5H: run `plot_weight_change.py`.
